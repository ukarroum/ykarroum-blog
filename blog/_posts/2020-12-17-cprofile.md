---
layout: post
title: 'Python Internals Serie : cProfile'
---

In this article, we will revisit _CPython_ code. This time we'll dive into cProfile's code to have more insights about its interal functionning.

I'll try to explain every notion used in this article and give links to sources whenevr possible, basic knowledge of Python and C is recommended but not mandatory.

## cProfile

cProfile is, well, a profiler. More seriously a profiler is a tool that can help us to determine how much time is spent in each function of our program.

This is especially useful if you want to decrease the running time of a program, using a profiler can help you find the botelneck and decide on which function you should invest developping time.

Anectodotal fact : i used to work on a ptoject that used Machine Learning in Python, and one of the tasks i was assigned was to optimize the time execution. Intuitively you may be tempted to optimize the learning step since it's utusally the one that take the most time, and manhy people tried without a lot of success, but after using a profiler we found that the learning part was actually very optimized and very quick (for reference we used XGBoost library) and a big chunk of the time was actually spent on pre processing steps. Which made our efforts more efficient to solve our performance issue.

There are two main types of profiling : 

- Deterministic profiling : Where you basically compute the time spent in each function, this has the advantage of being the most precise since you''re measuring exactly what you want to see, but can add a significant overhead to your program which may fake the results, of course this depends on how the profiling is done.
- statistical profiling : ....

cProfile is a deterministic profiler, but fortunatly is not slow cause ....

## Profiling a program using cProfile

using cProfile is fairly easy : 

{% highlight python %}
import cProfile
import re
cProfile.run('re.compile("foo|bar")')
{% endhighlight %}

This will print the following : 

{% highlight python %}
>>> cProfile.run('re.compile("foo|bar")')
         244 function calls (237 primitive calls) in 0.001 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.001    0.001 <string>:1(<module>)
        2    0.000    0.000    0.000    0.000 enum.py:278(__call__)
        2    0.000    0.000    0.000    0.000 enum.py:557(__new__)
        9    0.000    0.000    0.000    0.000 enum.py:654(name)
{% endhighlight %}

the columns refer to : 


> ncalls : for the number of calls.
> 
> tottime : for the total time spent in the given function (and excluding time made in calls to sub-functions)
> 
> percall : is the quotient of tottime divided by ncalls
> 
> cumtime : is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.
> 
> percall : is the quotient of cumtime divided by primitive calls
> 
> filename:lineno(function) : provides the respective data of each function

You can find this and more examples in the official documentation: [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html).

## MEDIUM_VALUE(x)

{% highlight c %}
/* convert a PyLong of size 1, 0 or -1 to an sdigit */
#define MEDIUM_VALUE(x) (assert(-1 <= Py_SIZE(x) && Py_SIZE(x) <= 1),   \
         Py_SIZE(x) < 0 ? -(sdigit)(x)->ob_digit[0] :   \
             (Py_SIZE(x) == 0 ? (sdigit)0 :                             \
              (sdigit)(x)->ob_digit[0]))
{% endhighlight %}

The comment is pretty straightforward, the macro convert a given _long_ to an _sdigit_. But what's an sdigit ? Well it depends : 

{% highlight c %}
#if PYLONG_BITS_IN_DIGIT == 30 /* signed variant of digit */
typedef int32_t sdigit
#elif PYLONG_BITS_IN_DIGIT == 15
typedef short sdigit; /* signed variant of digit */
#else
#error "PYLONG_BITS_IN_DIGIT should be 15 or 30
#endif

{% endhighlight %}

The `PYLONG_BITS_IN_DIGIT` is defined either at configure time or in `pyport.h`.

We have an assert to protect us from accidently casting a big integer to a sdigit, which may result in a loss of information, therefore potentiely issues which can be hard to fix.

Curiously, the assert check that the _size_ of x is bigger than -1, but can be less than 0 ? My guess is that size is unsigned to reflect the sign of the int, for exemple : `PY_SIZE(-15) = -2`.
This seems to be confirmed with `Py_SIZE(x) < 0 ? -(sdigit)(x)->ob_digit[0]`.

`ob_digit` looks like an array containing our integer. which can be confirmed in the file `longintrepr.h` : 

{% highlight c %}
struct _longobject {
    PyObject_VAR_HEAD
    digit ob_digit[1];
};
{% endhighlight %}

Im not sure why use an array of one element instead of just an integer `digit num`.


## IS_SMALL_INT(ival)

{% highlight c %}
#define IS_SMALL_INT(ival) (-NSMALLNEGINTS <= (ival) && (ival) < NSMALLPOSINTS)
{% endhighlight %}

Pretty straightforward function.

`NSMALLPOSINTS` and `NSMALLNEGINTS` is defined in the `pycore_interp.h` file : 

{% highlight c %}
/* interpreter state */

#define _PY_NSMALLPOSINTS           257
#define _PY_NSMALLNEGINTS           5
{% endhighlight %}

To undesrtand why those 2 magic numbers and and where the two macros are used, let's dive into the next function.
	
## static PyObject * get_small_int(sdigit ival)
{% highlight c %}
static PyObject *
get_small_int(sdigit ival)
{
    assert(IS_SMALL_INT(ival));
    PyInterpreterState *interp = _PyInterpreterState_GET();
    PyObject *v = (PyObject*)interp->small_ints[ival + NSMALLNEGINTS];
    Py_INCREF(v);
    return v;
}
{% endhighlight %}

This function implements what is commonly known as the _Flyweight pattern_, as explained here : [https://python-patterns.guide/gang-of-four/flyweight/](https://python-patterns.guide/gang-of-four/flyweight/), the flyweight pattern is used in python to create at the initialisation phase all the integers in the range [-5, 256]. At the runtime, whenever you ask for a number in this range, you'll always get the _same_ number.

Which can be easily checked : 

{% highlight python %}

20 + 30 is 50 # True
200 + 300 is 500 # False

{% endhighlight %}


Those integers objects are stored in the interpreter state.

According to [https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/](https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/) : 

> An interpreter state is a group of threads along with the data specific to this group. Threads share such things as loaded modules (sys.modules), builtins (builtins.__dict__) and the import system (importlib). 

Apparently flyweight integers are stored there.

We also use `Py_INCREF` to increment the reference count of the returned integer, recall that reference counting is what is used by the CPython garbage collector to detect which objects to free (Well not just that, since reference counting alone doesn't resolve circular references).


